{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25 \n",
    "IMAGE_SIZE = [150, 150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "for r, d, f in os.walk('../input/chest_xray/train'):\n",
    "     for file in f:\n",
    "        if file.endswith(\".jpeg\"):\n",
    "            train_images.append((os.path.join(r, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "for i in range(len(train_images)):\n",
    "    if 'bacteria' in train_images[i]:\n",
    "        train_labels.append((train_images[i],'BACTERIAL'))\n",
    "    elif 'virus' in train_images[i]:\n",
    "        train_labels.append((train_images[i],'VIRUS'))\n",
    "    else:\n",
    "        train_labels.append((train_images[i],'NORMAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_labels, columns = ['IMAGE','LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for r, d, f in os.walk('../input/chest_xray/test'):\n",
    "     for file in f:\n",
    "        if file.endswith(\".jpeg\"):\n",
    "            test_images.append((os.path.join(r, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "for i in range(len(test_images)):\n",
    "    if 'bacteria' in test_images[i]:\n",
    "        test_labels.append((test_images[i],'BACTERIAL'))\n",
    "    elif 'virus' in test_images[i]:\n",
    "        test_labels.append((test_images[i],'VIRUS'))\n",
    "    else:\n",
    "        test_labels.append((test_images[i],'NORMAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(test_labels, columns =['IMAGE','LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = []\n",
    "for r, d, f in os.walk('../input/chest_xray/val'):\n",
    "     for file in f:\n",
    "        if file.endswith(\".jpeg\"):\n",
    "            val_images.append((os.path.join(r, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for i in range(len(val_images)):\n",
    "    if 'bacteria' in val_images[i]:\n",
    "        val_labels.append((val_images[i],'BACTERIAL'))\n",
    "    elif 'virus' in val_images[i]:\n",
    "        val_labels.append((val_images[i],'VIRUS'))\n",
    "    else:\n",
    "        val_labels.append((val_images[i],'NORMAL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(val_labels, columns = ['IMAGE','LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df, x_col=\"IMAGE\", y_col=\"LABEL\",\n",
    "    target_size=(150,150),\n",
    "    color_mode='grayscale', #we use grayscale images I think\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    rescale=1.0/255,\n",
    "    seed=8)\n",
    "data_list = []\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= train_generator.batch_index:\n",
    "    data = train_generator.next()\n",
    "    data_list.append(data[0])\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "# now, data_array is the numeric data of whole images\n",
    "train_ds = np.asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = train_datagen.flow_from_dataframe(\n",
    "    test_df, x_col=\"IMAGE\", y_col=\"LABEL\",\n",
    "    target_size=(150,150),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    rescale=1.0/255,\n",
    "    seed=8)\n",
    "data_list = []\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= test_generator.batch_index:\n",
    "    data = test_generator.next()\n",
    "    data_list.append(data[0])\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "# now, data_array is the numeric data of whole images\n",
    "test_ds = np.asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    val_df, x_col=\"IMAGE\", y_col=\"LABEL\",\n",
    "    target_size=(150,150),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    rescale=1.0/255,\n",
    "    seed=8)\n",
    "data_list = []\n",
    "batch_index = 0\n",
    "\n",
    "while batch_index <= val_generator.batch_index:\n",
    "    data = val_generator.next()\n",
    "    data_list.append(data[0])\n",
    "    batch_index = batch_index + 1\n",
    "\n",
    "# now, data_array is the numeric data of whole images\n",
    "val_ds = np.asarray(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(filters, inputs):\n",
    "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = layers.SeparableConv2D(filters, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.MaxPool2D()(x)\n",
    "    return outputs\n",
    "\n",
    "def dense_block(units, dropout_rate, inputs):\n",
    "    x = layers.Dense(units, activation=\"relu\")(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dropout(dropout_rate)(x)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
    "    x = preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPool2D()(x)\n",
    "\n",
    "    x = conv_block(32, x)\n",
    "    x = conv_block(64, x)\n",
    "\n",
    "    x = conv_block(128, x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = conv_block(256, x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = dense_block(512, 0.7, x)\n",
    "    x = dense_block(128, 0.5, x)\n",
    "    x = dense_block(64, 0.3, x)\n",
    "\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience = 10, restore_best_weights = True\n",
    ")\n",
    "\n",
    "initial_learning_rate = 0.015\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps = 100000, decay_rate = 0.96, staircase = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Dima/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass classes=['BACTERIAL' 'NORMAL' 'VIRUS'], y=0       BACTERIAL\n",
      "1       BACTERIAL\n",
      "2       BACTERIAL\n",
      "3           VIRUS\n",
      "4       BACTERIAL\n",
      "          ...    \n",
      "5211       NORMAL\n",
      "5212       NORMAL\n",
      "5213       NORMAL\n",
      "5214       NORMAL\n",
      "5215       NORMAL\n",
      "Name: LABEL, Length: 5216, dtype: object as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_df['LABEL']),\n",
    "                                                 train_df['LABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2ee20288c86f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1040\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m       val_x, val_y, val_sample_weight = (\n\u001b[1;32m   1044\u001b[0m           data_adapter.unpack_x_y_sample_weight(validation_data))\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.BinaryAccuracy(),\n",
    "    tf.keras.metrics.Precision(name = \"precision\"),\n",
    "    tf.keras.metrics.Recall(name = \"recall\"),\n",
    "    tf.keras.metrics.AUC(name = \"AUC\"),\n",
    "    ]\n",
    "\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule),\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = METRICS,\n",
    "    )\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs = 100,\n",
    "    validation_data = val_ds,\n",
    "    class_weight = class_weight,\n",
    "    callbacks = [early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
